{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.journalfeed.LaTeX import *\n",
    "from bs4 import BeautifulSoup  # used to get rid of HTML stuff\n",
    "import html2text\n",
    "\n",
    "from src.journalfeed.config import load_config\n",
    "import src.journalfeed.arxiv as arxiv\n",
    "import src.journalfeed.nature as nature\n",
    "import src.journalfeed.science as science\n",
    "import src.journalfeed.aps as aps\n",
    "import datetime\n",
    "\n",
    "# sources, _filter, preamble = load_config()\n",
    "get_arxivarticles = arxiv.get_articles\n",
    "def arxiv_summary(aid, el=True):\n",
    "    return arxiv.get_articles(query=\"\", id_list=aid, ensure_latex=el)[0].summary\n",
    "\n",
    "# enddate = datetime.date.today()\n",
    "# timedelta = datetime.timedelta(days=7)\n",
    "# startdate = enddate - timedelta\n",
    "# naturearticles = nature.get_articles(journals=sources[\"nature\"][\"weekly\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local config \"filter.json\".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources, _filter, preamble = load_config()\n",
    "# get_arxivarticles(query=\"\", id_list=\"2111.04167v1\", ensure_latex=False)[0].match(*_filter)\n",
    "journals, authors, title_res, summary_res = _filter\n",
    "get_arxivarticles(query=\"\", id_list=\"2111.04167v1\", ensure_latex=False)[0].match(*_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hall effect measurements in doped polymer semiconductors are widely reported,\\nbut are difficult to interpret due to screening of Hall voltages by carriers\\nundergoing incoherent transport. Here, we propose a refined analysis for such\\nHall measurements, based on measuring the Hall coefficient as a function of\\ntemperature, and modelling carriers as existing in a regime of variable\\n\"deflectability\" (i.e. how strongly they \"feel\" the magnetic part of the\\nLorentz force). By linearly interpolating each carrier between the extremes of\\nno deflection and full deflection, we demonstrate that it is possible to\\nextract the (time-averaged) concentration of deflectable charge carriers,\\n$\\\\left<n_d\\\\right>$, the average, temperature-dependent mobility of those\\ncarriers, $\\\\left<\\\\mu_d\\\\right>(T)$, as well as the ratio of conductivity that\\ncomes from such deflectable transport, $d(T)$. Our method was enabled by the\\nconstruction of an improved AC Hall measurement system, as well as an improved\\ndata extraction method. We measured Hall bar devices of ion-exchange doped\\nfilms of PBTTT-C$_{14}$ from 10--300 K. Our analysis provides evidence for the\\nproportion of conductivity arising from deflectable transport, $d(T)$,\\nincreasing with doping level, ranging between 15.4% and 16.4% at room\\ntemperature. When compared to total charge-carrier-density estimates from\\nindependent methods, the values of $\\\\left<n_d\\\\right>$ extracted suggest that\\ncarriers spend $\\\\sim$37% of their time of flight being deflectable in the most\\nhighly doped of the devices measured here. The extracted values of $d(T)$ being\\nless than half this value thus suggest that the limiting factor for\\nconductivity in such highly doped devices is carrier mobility, rather than\\nconcentration.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = get_arxivarticles(query=\"\", id_list=\"2303.14053v1\", ensure_latex=False)[0].summary\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hall effect measurements in doped polymer semiconductors are widely reported,\\nbut are difficult to interpret due to screening of Hall voltages by carriers\\nundergoing incoherent transport. Here, we propose a refined analysis for such\\nHall measurements, based on measuring the Hall coefficient as a function of\\ntemperature, and modelling carriers as existing in a regime of variable\\n\"deflectability\" (i.e. how strongly they \"feel\" the magnetic part of the\\nLorentz force). By linearly interpolating each carrier between the extremes of\\nno deflection and full deflection, we demonstrate that it is possible to\\nextract the (time-averaged) concentration of deflectable charge carriers,\\n$\\\\left$, the average, temperature-dependent mobility of those carriers,\\n$\\\\left<\\\\mu_d\\\\right>(T)$, as well as the ratio of conductivity that comes from\\nsuch deflectable transport, $d(T)$. Our method was enabled by the construction\\nof an improved AC Hall measurement system, as well as an improved data\\nextraction method. We measured Hall bar devices of ion-exchange doped films of\\nPBTTT-C$_{14}$ from 10--300 K. Our analysis provides evidence for the\\nproportion of conductivity arising from deflectable transport, $d(T)$,\\nincreasing with doping level, ranging between 15.4% and 16.4% at room\\ntemperature. When compared to total charge-carrier-density estimates from\\nindependent methods, the values of $\\\\left$ extracted suggest that carriers\\nspend $\\\\sim$37% of their time of flight being deflectable in the most highly\\ndoped of the devices measured here. The extracted values of $d(T)$ being less\\nthan half this value thus suggest that the limiting factor for conductivity in\\nsuch highly doped devices is carrier mobility, rather than concentration.\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = html2text.html2text(s)\n",
    "# ret = re.sub(\"\\\\$\\\\\\\\require\\\\{[^\\\\]\\\\}]+\\\\}\\\\$\", \"\", ret)\n",
    "# ret = re.sub(\"\\\\\\\\\\\\$\", \"ESCAPEDDOLLAR\", ret)\n",
    "ret\n",
    "# math_matches = find_all_math(ret)\n",
    "# math_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-911350a2aafb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_arxivarticles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2303.14053v1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_latex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repos/journalfeed2pdf/src/journalfeed/arxiv.py\u001b[0m in \u001b[0;36mget_articles\u001b[0;34m(enddate, startdate, query, id_list, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mpublished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublished_parsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             articles.append(Article(e.title.replace(\"\\n\", \"\"), e.link, published,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                          \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                          \"arXiv\", **kwargs))\n",
      "\u001b[0;32m~/repos/journalfeed2pdf/src/journalfeed/Article.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, title, url, date, authors, summary, journal, ensure_latex)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_elc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/journalfeed2pdf/src/journalfeed/Article.py\u001b[0m in \u001b[0;36m_elc\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_elc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mensure_latex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0melc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/journalfeed2pdf/src/journalfeed/LaTeX.py\u001b[0m in \u001b[0;36melc\u001b[0;34m(s, general_sub, outside_math_sub, inside_math_sub, math_command_whitlist_regex, math_env_whitelist)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m# first use BeautifulSoup to get rid of html artefacts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# using html because beautifulsoup also strips <expecation values> in this form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;31m# require is used in math by MATHJAX to load additional packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;31m# Strip it because we use real latex and strip all unknown commands in the following\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nix/store/kzg2s1sa16l7bzda7rsf21g9zwc13v7i-python3-3.8.6-env/lib/python3.8/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mbuilder_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuilder_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m                 raise FeatureNotFound(\n\u001b[0m\u001b[1;32m    244\u001b[0m                     \u001b[0;34m\"Couldn't find a tree builder with the features you \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                     \u001b[0;34m\"requested: %s. Do you need to install a parser library?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "get_arxivarticles(query=\"\", id_list=\"2303.14053v1\", ensure_latex=True)[0].summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$$'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elc(\"$\\\\left<n_d\\\\right>$\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$<n_d>$'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_command_whitlist_regex = \"(\"+\"|\".join(math_command_whitelist)+\")\"\n",
    "test = \"$\\\\left<n_d\\\\right>$\"\n",
    "for find, replace in inside_math_sub:\n",
    "            test = re.sub(find, replace, test)\n",
    "test = re.sub(math_command_whitlist_regex+\"(\\\\\\\\|[0-9]|/)\", \"\\\\1 \\\\2\", test)\n",
    "test = re.sub(\"\\\\\\\\\"+math_command_whitlist_regex+\"(\\\\s|\\\\^|_|\\\\{|\\\\}|\\\\(|\\\\)|\\\\[|\\\\]|=|\\\\Z)\", \"\\\\\\\\\\\\\\\\\\\\1\\\\2\", test)\n",
    "regex = \"(\\\\\\\\begin\\\\{(?P<env>\"+\"|\".join(math_env_whitelist)+\")\\\\*?\\\\})(.+(?!(?P=env)))(\\\\\\\\end\\\\{(?P=env)\\\\*?\\\\})\"\n",
    "test = re.sub(regex, \"\\\\\\\\\\\\1\\\\3\\\\\\\\\\\\4\", test)\n",
    "test = re.sub(\"\\\\\\\\([a-zA-Z0-9])\", \"\\\\1\", test)\n",
    "\n",
    "    \n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enddate = datetime.date(2021, 11, 4)\n",
    "timedelta = datetime.timedelta(days=7)\n",
    "startdate = enddate - timedelta\n",
    "\n",
    "sciencearticles = science.get_articles(journals=sources[\"science\"][\"weekly\"],\n",
    "                                       enddate=enddate, startdate=startdate)\n",
    "len(sciencearticles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In Other Journals'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sciencearticles[1].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\\\\\textbf\\\\{\\\\}'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.escape(\"\\\\textbf{}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\{\\\\}'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.escape(\"{}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
